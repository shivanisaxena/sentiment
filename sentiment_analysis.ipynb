{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivanisaxena/sentiment/blob/master/sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaDn6JY3pP5U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras.callbacks\n",
        "import tensorflow as tf\n",
        "from keras.layers import Dense, Input, Dropout, MaxPooling1D, Conv1D, GlobalMaxPool1D\n",
        "from keras.layers import LSTM, Lambda, concatenate, TimeDistributed, Bidirectional"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "But1C6dppThw",
        "colab_type": "code",
        "outputId": "7ccf7abe-0bd3-4389-eee5-28e310df7bd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YW1SRaKOpgKA",
        "colab_type": "code",
        "outputId": "fae24860-a8bf-437e-8052-8c07586c9d69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from keras.layers import Input, Embedding, Activation, Flatten, Dense\n",
        "from keras.layers import Conv1D, MaxPooling1D, Dropout\n",
        "from keras.models import Model\n",
        "from keras.layers import LeakyReLU"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5eGTn39pheE",
        "colab_type": "code",
        "outputId": "20cc69fa-97f7-4f2e-ebe2-23a2abcb5d06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import re\n",
        "with open('/content/drive/My Drive/sentiment_analysis/train.txt') as fp:\n",
        "\tlineList = fp.readlines()\n",
        "\n",
        "tempTrainData = []\n",
        "tempList = []\n",
        "for item in lineList:\n",
        "\titem = re.sub(r'\\t',' ',item)\n",
        "\titem = re.sub(r'\\n','',item)\n",
        "\ttemp = item.split(' ')\n",
        "\tif len(temp)==3:\n",
        "\t\ttempTrainData.append(tempList)\n",
        "\t\ttempTrainData.append([temp[2]])\n",
        "\t\ttempList = [' ']\n",
        "\telse:\n",
        "\t\ttempList.append(temp[0])\n",
        "\n",
        "trainData = np.array(tempTrainData)\n",
        "\n",
        "dataList = []\n",
        "sentiList = []\n",
        "\n",
        "for i in range(len(trainData)):\n",
        "\ts = ''\n",
        "\tfor item in trainData[i]:\n",
        "\t\ts = s+' '+item\n",
        "\t\n",
        "\tif s == '' or s == ' ':\n",
        "\t\tpass\n",
        "\telif s == ' positive' or s== ' negative' or s==' neutral':\n",
        "\t\ts = re.sub(r'','',s)\n",
        "\t\tsentiList.append(s)\n",
        "\telse:\n",
        "\t\tdataList.append(s)\n",
        "\n",
        "del sentiList[len(sentiList)-1]\n",
        "\n",
        "print(len(sentiList),sentiList[0])\n",
        "print(len(dataList),dataList[0])"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15130  negative\n",
            "15130    @ AdilNisarButt pakistan ka ghra tauq he Pakistan Israel ko tasleem nahein kerta Isko Palestine kehta he - OCCUPIED PALESTINE \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPPPDXvupqnd",
        "colab_type": "code",
        "outputId": "da21b40d-207b-4076-e9af-369c024c08d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "with open('/content/drive/My Drive/sentiment_analysis/test.txt') as fp:\n",
        "\tlineList = fp.readlines()\n",
        "\n",
        "tempTestData = []\n",
        "tempTestList = []\n",
        "for item in lineList:\n",
        "\titem = re.sub(r'\\t',' ',item)\n",
        "\titem = re.sub(r'\\n','',item)\n",
        "\ttemp = item.split(' ')\n",
        "\tif len(temp)==3:\n",
        "\t\ttempTestData.append(tempTestList)\n",
        "\t\ttempTestData.append([temp[2]])\n",
        "\t\ttempTestList = [' ']\n",
        "\telse:\n",
        "\t\ttempTestList.append(temp[0])\n",
        "\n",
        "testData = np.array(tempTestData)\n",
        "\n",
        "dataTestList = []\n",
        "sentiTestList = []\n",
        "\n",
        "for i in range(len(testData)):\n",
        "\ts = ''\n",
        "\tfor item in testData[i]:\n",
        "\t\ts = s+' '+item\n",
        "\t\n",
        "\tif s == '' or s == ' ':\n",
        "\t\tpass\n",
        "\telif s == ' positive' or s== ' negative' or s==' neutral':\n",
        "\t\ts = re.sub(r'','',s)\n",
        "\t\tsentiTestList.append(s)\n",
        "\telse:\n",
        "\t\tdataTestList.append(s)\n",
        "\n",
        "del sentiTestList[len(sentiTestList)-1]\n",
        "\n",
        "train_arr=dataList\n",
        "test_arr=dataTestList\n",
        "train_arr_senti=sentiList\n",
        "test_arr_senti=sentiTestList\n",
        "\n",
        "print(len(test_arr),test_arr[0])\n",
        "print(len(test_arr_senti),test_arr_senti[0])"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1868    RT @ UAAPconfessions Love looks good on Maddie !!! Ako lang ba yung sobrang masaya kasi may zolo sya ? Before with the past Z medyo lowkey s â€¦ \n",
            "1868  neutral\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvAhp8rbp2aJ",
        "colab_type": "code",
        "outputId": "3f1e2baa-4fae-4f95-c61a-7299874b9630",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "\n",
        "train_texts = train_arr[:]\n",
        "train_texts = [s.lower() for s in train_texts]\n",
        "\n",
        "test_texts = test_arr[:]\n",
        "test_texts = [s.lower() for s in test_texts]\n",
        "\n",
        "tk = Tokenizer(num_words=None, char_level=True, oov_token='UNK')\n",
        "tk.fit_on_texts(train_texts)\n",
        "\n",
        "train_sequences = tk.texts_to_sequences(train_texts)\n",
        "test_texts = tk.texts_to_sequences(test_texts)\n",
        "train_data = pad_sequences(train_sequences, maxlen=170, padding='post')\n",
        "test_data = pad_sequences(test_texts, maxlen=170, padding='post')\n",
        "train_data = np.array(train_data)\n",
        "test_data = np.array(test_data)\n",
        "train_classes_1 = train_arr_senti[:]\n",
        "train_class_list = []\n",
        "\n",
        "for i in train_classes_1:\n",
        "  if(i == ' positive'):\n",
        "    train_class_list.append(0)\n",
        "  elif(i == ' negative'):\n",
        "    train_class_list.append(2)\n",
        "  else:\n",
        "    train_class_list.append(1)\n",
        "\n",
        "train_class_list = np.array(train_class_list)\n",
        "\n",
        "test_classes_1 = test_arr_senti[:]\n",
        "test_class_list = []\n",
        "\n",
        "for i in test_classes_1:\n",
        "  if(i == ' positive'):\n",
        "    test_class_list.append(0)\n",
        "  elif(i == ' negative'):\n",
        "    test_class_list.append(2)\n",
        "  else:\n",
        "    test_class_list.append(1)\n",
        "\n",
        "test_class_list = np.array(test_class_list)\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "train_classes = to_categorical(train_class_list)\n",
        "test_classes = to_categorical(test_class_list)\n",
        "print(train_classes)\n",
        "print(test_classes)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " ...\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]]\n",
            "[[0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " ...\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7XEcE4_p-JV",
        "colab_type": "code",
        "outputId": "bfece62e-bfda-44c4-b8bf-86c6b6a590d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# char CNN\n",
        "input_size = 170\n",
        "vocab_size = len(tk.word_index)\n",
        "print(tk.word_index)\n",
        "embedding_size = 899\n",
        "conv_layers = [[256, 3, 3],\n",
        "               [256, 3, 3],\n",
        "               [256, 3, -1],\n",
        "               [256, 3, -1],\n",
        "               [256, 3, -1],\n",
        "               [256, 3, 3]]\n",
        "\n",
        "fully_connected_layers = [1024, 1024]\n",
        "num_of_classes = 3\n",
        "dropout_p = 0.5\n",
        "optimizer = 'Adamax'\n",
        "loss = 'categorical_crossentropy'\n",
        "\n",
        "# Embedding weights\n",
        "embedding_weights = [] \n",
        "embedding_weights.append(np.zeros(vocab_size))  \n",
        "\n",
        "for char, i in tk.word_index.items():\n",
        "    onehot = np.zeros(vocab_size)\n",
        "    onehot[i - 1] = 1\n",
        "    embedding_weights.append(onehot)\n",
        "\n",
        "embedding_weights = np.array(embedding_weights)\n",
        "embedding_layer = Embedding(vocab_size+1,embedding_size, weights=[embedding_weights])\n",
        "inputs = Input(shape=(input_size,), name='input', dtype='int64') \n",
        "x = embedding_layer(inputs)\n",
        "for filter_num, filter_size, pooling_size in conv_layers:\n",
        "    x = Conv1D(filter_num, filter_size)(x)\n",
        "    x = LeakyReLU(alpha=0.05)(x)\n",
        "    if pooling_size != -1:\n",
        "        x = MaxPooling1D(pool_size=pooling_size)(x)  \n",
        "\n",
        "x = Flatten()(x)\n",
        "\n",
        "for dense_size in fully_connected_layers:\n",
        "    x = Dense(dense_size, activation='linear')(x)\n",
        "    x = LeakyReLU(alpha=0.05)(x)\n",
        "    x = Dropout(dropout_p)(x)\n",
        "\n",
        "predictions = Dense(num_of_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=predictions)\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy']) \n",
        "model.summary()\n",
        "\n",
        "x_test = test_data\n",
        "y_test = test_classes\n"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'UNK': 1, ' ': 2, 'a': 3, 'i': 4, 'e': 5, 'h': 6, 't': 7, 'o': 8, 'r': 9, 's': 10, 'n': 11, 'k': 12, 'm': 13, 'l': 14, 'd': 15, 'u': 16, 'p': 17, 'b': 18, 'y': 19, 'c': 20, 'g': 21, '/': 22, '@': 23, '.': 24, 'j': 25, 'w': 26, 'f': 27, 'v': 28, 'â€¦': 29, 'z': 30, '_': 31, '1': 32, '0': 33, 'q': 34, '2': 35, 'x': 36, '3': 37, '9': 38, '5': 39, '4': 40, '7': 41, '8': 42, '6': 43, '#': 44, '!': 45, 'ğŸ˜‚': 46, '?': 47, \"'\": 48, '-': 49, 'â€™': 50, 'ï¸': 51, 'ğŸ™': 52, 'â¤': 53, 'ğŸ¤£': 54, 'ğŸ˜': 55, '&': 56, ')': 57, '(': 58, 'ğŸ˜­': 59, '*': 60, 'ğŸ˜˜': 61, 'ğŸ‡®': 62, 'ğŸ‡³': 63, 'ğŸ˜Š': 64, 'ğŸŒ¹': 65, 'ğŸ’œ': 66, 'ğŸ‚': 67, 'â€œ': 68, 'ğŸ’•': 69, 'à¤¾': 70, 'ğŸ˜': 71, 'ğŸ‘': 72, 'ğŸ‰': 73, 'ğŸ’–': 74, 'ğŸ‘': 75, '|': 76, 'ğŸ‘Œ': 77, 'â€': 78, 'âœŒ': 79, 'ğŸ˜œ': 80, '%': 81, 'à¤°': 82, 'ğŸ˜†': 83, 'ğŸ’': 84, 'ğŸ»': 85, '+': 86, 'â™¥': 87, 'ğŸ¤—': 88, 'à¥': 89, 'ğŸ˜': 90, 'ğŸ˜¡': 91, 'ğŸ™„': 92, 'ğŸ”¥': 93, '~': 94, 'ğŸ¤”': 95, '\\u200d': 96, 'ğŸ˜‰': 97, 'ğŸ’™': 98, 'ğŸ˜ ': 99, 'ğŸ˜…': 100, 'ğŸ™Œ': 101, '\\U0001f92a': 102, 'ğŸ˜€': 103, 'à¤¨': 104, 'à¤•': 105, 'à¤®': 106, ';': 107, 'ğŸŒ¸': 108, 'ğŸ’“': 109, 'à¥€': 110, 'ğŸ˜‹': 111, 'à¤¸': 112, 'ğŸ’”': 113, 'â˜º': 114, 'â€˜': 115, 'ğŸ˜¢': 116, 'ğŸ˜Œ': 117, 'â€”': 118, '\\U0001f970': 119, 'à¥‡': 120, 'ğŸ’': 121, 'ğŸ’ª': 122, 'ğŸ˜': 123, 'à¤¹': 124, 'ğŸ˜”': 125, 'à¤¤': 126, 'ğŸ’¯': 127, 'ğŸ’—': 128, 'ğŸ˜’': 129, 'ğŸ˜‘': 130, 'ğŸ˜„': 131, '\\xa0': 132, 'ğŸ™ˆ': 133, '[': 134, 'ğŸš©': 135, 'ğŸŒ·': 136, 'ğŸŠ': 137, 'à¤‚': 138, 'ğŸ˜‡': 139, '=': 140, 'ğŸ˜ª': 141, 'ğŸ‘‡': 142, 'ğŸŒº': 143, 'ğŸ˜¹': 144, 'Ã©': 145, ']': 146, 'à¤¯': 147, 'ğŸ˜›': 148, 'à¤¿': 149, 'ğŸ˜': 150, 'ğŸ¼': 151, 'ğŸ™‚': 152, '>': 153, 'ğŸ˜¬': 154, 'ğŸ': 155, 'ğŸ˜ƒ': 156, 'à¤—': 157, 'à¤ª': 158, 'à¤¬': 159, '\\U0001f929': 160, 'ğŸ’š': 161, 'ğŸ˜¤': 162, 'ğŸ˜': 163, 'Ã¡': 164, 'ğŸˆ': 165, 'ğŸ½': 166, 'ğŸ˜•': 167, '$': 168, 'ğŸ’': 169, 'Ø§': 170, 'ğŸ†': 171, 'ğŸ˜©': 172, 'ğŸ¤¦': 173, '<': 174, 'à¤¦': 175, 'ğŸ‡µ': 176, 'ğŸ‡°': 177, '\"': 178, 'â™‚': 179, 'Ä': 180, 'à¤µ': 181, '\\U0001f928': 182, 'â™€': 183, 'ğŸ™Š': 184, 'à¤œ': 185, 'â˜¹': 186, 'ğŸ’ƒ': 187, 'à¥': 188, 'à¤²': 189, '\\U0001f97a': 190, 'ğŸ¾': 191, 'ğŸ–•': 192, 'ğŸ¤§': 193, 'à¥‹': 194, 'à¥‚': 195, 'ğŸ’': 196, 'âœ¨': 197, 'à¥ˆ': 198, '\\U0001f92c': 199, 'âœ…': 200, 'Ù„': 201, 'ğŸ’‹': 202, 'â£': 203, 'à¤¶': 204, 'ğŸŒˆ': 205, 'ğŸŒš': 206, 'Ù…': 207, 'Ã­': 208, 'ğŸ˜¶': 209, 'ğŸ˜ˆ': 210, 'Ø±': 211, 'ğŸ˜·': 212, 'ğŸ‘‰': 213, 'ğŸ’›': 214, 'ğŸ’˜': 215, 'â€“': 216, 'ğŸ˜£': 217, 'à¤­': 218, 'ğŸ˜³': 219, 'Ø¹': 220, 'ğŸ’®': 221, 'ğŸ”¯': 222, 'ğŸ‘‹': 223, 'ğŸ˜¨': 224, 'ğŸ˜': 225, '\\U0001f973': 226, 'Ä±': 227, 'ÛŒ': 228, 'ğŸ¤“': 229, 'ğŸµ': 230, 'ğŸ‘‘': 231, 'ğŸ˜¥': 232, 'ÅŸ': 233, 'ğŸ˜š': 234, 'á´‡': 235, 'Ùˆ': 236, 'à¤…': 237, 'ğŸŒ¼': 238, 'ğŸ˜´': 239, '`': 240, 'ğŸ¤˜': 241, 'ğŸ‘€': 242, '\\U000e0067': 243, 'ğŸ–¤': 244, 'âš«': 245, 'ğŸ˜“': 246, 'ğŸ™‰': 247, 'ğŸ¶': 248, 'ğŸ’¥': 249, 'ğŸ‘«': 250, 'Ã§': 251, 'ğŸ': 252, 'Ø¯': 253, 'à¤«': 254, 'ğŸŒ²': 255, 'à±': 256, 'â€¼': 257, 'ğŸ˜»': 258, 'ğŸŒ±': 259, 'Ã¥': 260, 'Ã¼': 261, 'ğŸ': 262, 'ğŸ¤·': 263, 'ğŸ’«': 264, 'à¤§': 265, 'ğŸ¦‹': 266, 'à¤Ÿ': 267, '\\U0001f932': 268, 'ğŸ‘»': 269, '\\U0001f9e1': 270, 'Ã±': 271, 'Ãª': 272, 'ğŸ«': 273, 'ğŸ¤': 274, 'ğŸ˜«': 275, 'ğŸ™‡': 276, 'á´€': 277, 'ğŸ¼': 278, 'ğŸ™ƒ': 279, 'à¤š': 280, 'âœŠ': 281, 'ğŸ’‘': 282, 'à¤–': 283, '\\U0001f92d': 284, 'ğŸ‘¦': 285, 'ğŸ‘ˆ': 286, 'ğŸµ': 287, 'ğŸ‘©': 288, 'â¡': 289, 'âœ–': 290, 'âœ”': 291, 'ğŸ˜±': 292, 'à¤¥': 293, 'ğŸ—¿': 294, 'ğŸ¤™': 295, 'Ø©': 296, 'Ù‚': 297, 'á´›': 298, 'ğŸŒ¿': 299, 'ğŸ™†': 300, 'à¤': 301, 'â€¢': 302, 'ğŸŒµ': 303, 'à°°': 304, 'Â´': 305, 'â›³': 306, 'à¤¡': 307, 'Ø¬': 308, 'â˜': 309, 'ğŸ‡¦': 310, 'ğŸ´': 311, '\\U000e0062': 312, '\\U000e007f': 313, 'Ã£': 314, 'ğŸ˜¯': 315, 'â“': 316, 'â—': 317, 'ğŸ§': 318, 'â‚¹': 319, 'ğŸ“„': 320, 'ğŸ“': 321, 'Éª': 322, 'É´': 323, 'á´': 324, 'âœ‹': 325, 'Øª': 326, 'Ú©': 327, 'ğŸ¤': 328, 'ğŸ‘­': 329, 'ğŸ˜Ÿ': 330, 'ğŸ°': 331, 'ğŸ˜®': 332, 'à°¿': 333, 'à°¾': 334, 'ğŸ”«': 335, 'ğŸ‘': 336, 'ğŸ±': 337, 'ğŸ³': 338, 'ğŸ˜°': 339, '\\U000e0065': 340, '\\U000e006e': 341, 'ğŸ–': 342, 'ğŸŒ™': 343, '{': 344, '}': 345, 'ğŸ’©': 346, 'à¹ˆ': 347, 'à¤ˆ': 348, '^': 349, 'Ø³': 350, 'â¬‡': 351, '\\U0001f92f': 352, 'Â¡': 353, 'â•­': 354, 'â•®': 355, 'ğŸ‘¨': 356, 'É©': 357, 'áµ’': 358, 'áµ‰': 359, 'ã®': 360, 'âœ': 361, 'ğ—²': 362, 'ğŸ˜—': 363, 'ğŸ‡': 364, 'Ã¤': 365, 'à¤·': 366, 'ğŸ‘°': 367, 'ğŸ‘¸': 368, 'Ê€': 369, 'Ã´': 370, 'Å‚': 371, 'ğŸ“ƒ': 372, '\\U0001f9da': 373, 'ğŸ‘¿': 374, 'à¤‡': 375, 'ğŸ‡º': 376, 'ğŸ‡¸': 377, 'ğŸ¾': 378, 'à¥Œ': 379, 'à°•': 380, 'à±': 381, 'à°¸': 382, 'à°‚': 383, 'à°¡': 384, 'à°ª': 385, 'ğŸ·': 386, 'ğŸ˜™': 387, 'ğŸ‡«': 388, 'ğŸ‡©': 389, 'ğŸ‡¿': 390, 'ğŸ‘Š': 391, 'ğŸ‡¬': 392, 'ğŸ’¸': 393, 'à¤†': 394, 'à¸„': 395, 'à¤¼': 396, 'ğŸš¨': 397, 'ğŸ¿': 398, '\\U0001f91f': 399, 'Û’': 400, 'Ä': 401, 'Ã½': 402, '\\U0001f9d0': 403, 'ğŸ”´': 404, 'à¥¤': 405, 'ğŸ™': 406, 'âŒ': 407, 'ğŸ‘ ': 408, 'ğŸ¤': 409, 'ğ„': 410, 'à¨‚': 411, 'Ù†': 412, 'ğŸŒŸ': 413, 'â¬†': 414, 'ğŸŒ»': 415, 'ğŸ€': 416, 'ğŸ”': 417, 'Ë¢': 418, 'ğŸ—£': 419, '\\u2066': 420, 'ğŸ’': 421, 'ãƒ³': 422, 'ãƒ¼': 423, '\\u200b': 424, 'ğ˜€': 425, 'ğŸ–': 426, 'ğŸ˜–': 427, 'áº¡': 428, 'áº½': 429, 'Ã³': 430, 'ğŸ¨': 431, 'ğŸ¬': 432, 'ğŸ¯': 433, 'ğŸŒ': 434, 'ğŸ‘¾': 435, 'ã… ': 436, 'ÙŠ': 437, 'â–º': 438, 'à¤£': 439, 'á´‹': 440, 'Ò“': 441, 'á´…': 442, 'ğŸ’¬': 443, 'á´': 444, 'á´˜': 445, 'Ä‘': 446, 'ğŸ’¡': 447, 'ğŸ’': 448, 'ğŸ¤¤': 449, 'Ø¨': 450, 'Å¼': 451, 'ğŸ™‹': 452, 'à¤›': 453, 'ï·º': 454, 'ğŸ“·': 455, 'à¤': 456, 'âƒ£': 457, 'ìŠ¤': 458, 'ï½“': 459, 'à°®': 460, 'à°¨': 461, 'à°¦': 462, 'à°¤': 463, 'à±‹': 464, 'à°¯': 465, 'à°²': 466, 'à°‰': 467, 'à°·': 468, 'à¥ƒ': 469, 'Å¯': 470, 'ğŸ‡§': 471, 'ğŸ‡±': 472, 'ğŸŒ´': 473, 'âœˆ': 474, 'ğŸ’Œ': 475, 'ğŸ‹': 476, 'Ûƒ': 477, 'ğŸ’€': 478, 'ê•Š': 479, 'ğ¡': 480, 'ğ': 481, 'à¸œ': 482, 'à¸™': 483, 'à¸›': 484, 'à¸µ': 485, 'à¸­': 486, 'à¸š': 487, 'à¸¸': 488, 'à¸—': 489, 'à¸': 490, '\\U0001f975': 491, 'ğŸš¬': 492, 'ğŸ¦‰': 493, 'Ø´': 494, 'ğŸ‘§': 495, 'ğŸŒ': 496, 'à¤ƒ': 497, 'ğŸ’…': 498, 'ğŸ¤’': 499, 'ï½¡': 500, 'â€¿': 501, 'â—‰': 502, 'ğŸ¦': 503, 'Ã¶': 504, 'Ã—': 505, 'ğŸš´': 506, 'ğŸš¶': 507, 'ğŸ§': 508, 'ğŸ¼': 509, 'ğŸ‚': 510, 'ğŸŒ¶': 511, 'Å™': 512, 'ğŸ': 513, 'ğŸŒ': 514, 'Â·': 515, 'Â¯': 516, 'ã£': 517, 'Ë˜': 518, 'Ì©': 519, 'ğŸ': 520, 'ğŸ': 521, 'â™¡': 522, 'âƒ‘': 523, 'Õ¬': 524, 'É£': 525, 'Ñ”': 526, 'É²': 527, 'à¨¹': 528, 'à©': 529, 'à¨¤': 530, 'à©€': 531, 'à¨°': 532, 'ğŸ¦': 533, 'Ãº': 534, 'ğŸŒ': 535, 'Â®': 536, 'ğŸ¬': 537, 'ğŸ‘º': 538, 'ê¸°': 539, 'ë‹¤': 540, 'â €': 541, 'ğŸ‡­': 542, 'ã€£': 543, 'Âº': 544, 'áµ': 545, 'Ê¸': 546, 'áµ': 547, 'áµ˜': 548, 'áµƒ': 549, 'á¶¦': 550, '\\u2069': 551, 'ãƒ€': 552, 'ãƒ’': 553, 'ãƒ§': 554, 'æ—¥': 555, 'é™': 556, 'å®š': 557, 'ã§': 558, 'ã™': 559, 'ğ—¶': 560, 'ğ—°': 561, 'ğŸƒ': 562, 'Ä«': 563, 'Ä“': 564, 'ğŸŒ˜': 565, 'â¤´': 566, 'Ğ°': 567, 'Ã®': 568, 'âœ´': 569, 'â”': 570, 'â‰': 571, 'â•': 572, 'Â¿': 573, 'ÄŸ': 574, 'ğŸ¤ ': 575, 'â˜ª': 576, 'ğŸ–': 577, 'ğŸ‘¼': 578, 'ÊŸ': 579, 'ğŸ‘¥': 580, 'É¢': 581, 'ğŸ’¾': 582, 'á´ ': 583, 'á´„': 584, 'Ê': 585, 'á´œ': 586, 'Êœ': 587, 'áº¿': 588, 'á»“': 589, 'á»§': 590, 'á»': 591, 'á»‘': 592, 'ğŸ‚': 593, 'Ø¦': 594, 'Ä‡': 595, 'Ä™': 596, 'Å›': 597, 'â†‘': 598, 'ğŸ”·': 599, 'ğŸ”¶': 600, 'ğŸ¸': 601, 'ğŸ‘†': 602, 'âœ‰': 603, 'ğŸ‡²': 604, 'ğŸ›': 605, 'ï·»': 606, '\\U0001f9c1': 607, 'ğŸ¥‚': 608, 'ğ¹': 609, 'ğ’¾': 610, 'ğ‘”': 611, 'ğ’½': 612, 'ğ“‰': 613, 'ğ’»': 614, 'ğ‘œ': 615, 'ğ“‡': 616, 'ğ“Š': 617, 'ğ“ˆ': 618, 'ğŸ“': 619, 'çŒ«': 620, 'ã­': 621, 'ã“': 622, 'ãƒ': 623, 'ã‚³': 624, 'ğŸ”': 625, 'ğŸ’£': 626, 'à¤‘': 627, 'í•œ': 628, 'êµ­': 629, 'ëŒ„': 630, 'ëŸ¬': 631, 'ì‹œ': 632, 'íŒ€': 633, 'ì•½': 634, 'ì': 635, 'ì œ': 636, 'ì¼': 637, 'ì€': 638, 'í–‰': 639, 'ï½•': 640, 'ï½': 641, 'ï½…': 642, 'ï½”': 643, 'ğŸˆ': 644, 'ğŸ¤š': 645, 'à°§': 646, 'à°¬': 647, 'à±‡': 648, 'à°‡': 649, 'à°…': 650, 'à±‚': 651, 'à°µ': 652, 'à°š': 653, 'ğŸ‡': 654, 'Ä›': 655, 'Å¡': 656, 'à¤ ': 657, 'ğŸ': 658, 'ğŸ¥ƒ': 659, 'ğŸ©': 660, 'ğŸ¦': 661, 'ğŸ•‹': 662, 'ğŸ—': 663, 'Ù‡': 664, 'ğŸ•º': 665, 'ğŸ•¯': 666, 'ğŸ™€': 667, 'à¥‰': 668, 'ğŸ˜²': 669, 'ğŸ”š': 670, 'ğŸ”¨': 671, 'ğŸ’': 672, 'ğ‚': 673, 'ğš': 674, 'ğ©': 675, 'ğ­': 676, 'ğ«': 677, 'ğŸ”': 678, 'ğŸ': 679, 'ğŸ': 680, 'ğ‰': 681, 'ğ®': 682, 'ğ§': 683, 'ğ–': 684, 'ğ¢': 685, 'ğ¬': 686, 'ï¸': 687, 'à¸²': 688, 'à¹„': 689, 'à¹': 690, 'à¸¥': 691, 'à¹‰': 692, 'à¸§': 693, 'à¸£': 694, 'à¸¶': 695, 'à¸‡': 696, 'à¸‚': 697, 'à¸“': 698, 'à¸¢': 699, 'à¸¹': 700, 'à¸±': 701, 'ğŸ¤‘': 702, 'Úº': 703, 'Û': 704, 'â˜…': 705, 'âš”': 706, 'ğŸ‡·': 707, 'â˜€': 708, '\\U0001f9f8': 709, 'Åˆ': 710, 'ğŸ‘': 711, 'ğŸ€': 712, 'ğŸ™…': 713, 'âšª': 714, '\\U000e0073': 715, '\\U000e0063': 716, '\\U000e0074': 717, 'ğŸ›': 718, 'Ã²': 719, 'Â£': 720, 'â‚¬': 721, 'â­': 722, 'Ã ': 723, 'ğŸ¦„': 724, 'ğŸ±': 725, 'âš½': 726, 'ğŸ‘': 727, '\\U0001f97e': 728, 'ğŸ‘Ÿ': 729, 'ğŸ˜¼': 730, 'ğŸŒŠ': 731, 'â„…': 732, 'ğŸ¥': 733, 'ğŸ¿': 734, 'ğŸ”ˆ': 735, 'ğŸ”ª': 736, 'âŒš': 737, 'â–‚': 738, 'ğŸŸ': 739, 'ğŸ‹': 740, 'ğŸ¶': 741, 'Â¥': 742, 'à¨£': 743, 'à¨¸': 744, 'à¨¨': 745, 'à¨•': 746, 'à©‹': 747, 'à¨—': 748, 'à©‡': 749, 'à¨¾': 750, 'à¨«': 751, 'à¨¿': 752, 'â€•': 753, 'Ã¬': 754, 'ğŸ‡¨': 755, 'ğŸŒ³': 756, 'Øº': 757, 'Ø·': 758, 'Ø®': 759, 'Ø²': 760, 'ğŸ®': 761, 'ğŸ”': 762, '\\U0001f9b3': 763, 'ğŸ“»': 764, 'ğŸŒ„': 765, 'â˜”': 766, 'Î¼': 767, 'ğŸ“': 768, 'â‡': 769, 'ğŸ‡ª': 770, 'à¦ˆ': 771, 'à¦¦': 772, 'à¦®': 773, 'à§‹': 774, 'à¦¬': 775, 'à¦¾': 776, 'à¦°': 777, 'à¦•': 778, 'Â°': 779, 'ì´': 780, 'ë‚˜': 781, 'ê²½': 782, 'ğŸ•': 783, 'ğŸ‘…': 784, 'Ú¯': 785, 'ğŸ””': 786, 'ğŸ”': 787, 'ğŸ¤¡': 788, 'ğŸ': 789, '\\U0001f96d': 790, 'ğŸ‘¹': 791, 'ğŸ“¿': 792, 'ë©€': 793, 'í‹°': 794, 'ë·°': 795, 'ì™€': 796, 'í•¨': 797, 'ê»˜': 798, 'ì¦': 799, 'ëŠ”': 800, 'ë¨¸': 801, 'í„°': 802, 'ì‹¤': 803, 'í™©': 804, 'ìƒ': 805, 'ì¤‘': 806, 'ê³„': 807, 'ë§Œ': 808, 'ë¦½': 809, 'ë‹ˆ': 810, 'ğŸ˜µ': 811, 'ğŸŸ': 812, 'ğŸ•Œ': 813, 'ğŸ’Ÿ': 814, 'à¤”': 815, 'ğŸ¡': 816, 'â›²': 817, 'Î´': 818, 'Ê°': 819, 'áµˆ': 820, 'Ê³': 821, 'á¶œ': 822, 'áµ—': 823, 'áµ›': 824, 'áµ': 825, 'ğŸ˜¿': 826, 'ğŸ¤•': 827, 'ğŸ¥': 828, 'ğŸ¤': 829, 'ğŸ”Ÿ': 830, 'ğŸ†': 831, 'ğŸ—': 832, 'ã¯': 833, 'ğŸ¦…': 834, 'èª•': 835, 'ç”Ÿ': 836, 'å½“': 837, 'ã€': 838, 'ã‚¤': 839, 'ãƒ™': 840, 'ãƒˆ': 841, 'ã‚¹': 842, 'ãƒ†': 843, 'ã‚¸': 844, 'ãŒ': 845, 'ã¤': 846, 'ã„': 847, 'ã«': 848, 'é–‹': 849, 'æ”¾': 850, 'ã¹': 851, 'ã¦': 852, 'ãƒ‘': 853, 'ã‚º': 854, 'ãƒ«': 855, 'ã‚’': 856, 'ã‚¯': 857, 'ãƒª': 858, 'ã‚¢': 859, 'ã‚‹': 860, 'ã¨': 861, 'ãƒ ': 862, 'ãƒ“': 863, 'ã¾': 864, 'á»‰': 865, 'Æ°': 866, 'á»': 867, 'â‡’': 868, 'â›½': 869, 'ğŸ‘¶': 870, 'ğ—£': 871, 'ğ˜‚': 872, 'ğ—¯': 873, 'ğ—¹': 874, 'ğ—¿': 875, 'ğ˜ƒ': 876, 'ğ—º': 877, 'ğ—®': 878, 'ğ—´': 879, 'ğŸ˜¦': 880, 'â„¢': 881, 'ğŸ“ˆ': 882, 'âš•': 883, 'ğŸ“£': 884, 'Ğ¼': 885, 'Ğ¾': 886, 'Ğ´': 887, 'Ğº': 888, 'Ñ€': 889, 'Ñ‚': 890, 'ğŸ‡¾': 891, 'Øµ': 892, 'ğŸŒŒ': 893, 'ğŸ‘’': 894, 'ğŸ¥‡': 895, 'âš˜': 896, 'ğŸ’': 897, '\\U0001f974': 898, '\\U0001f92e': 899}\n",
            "Model: \"model_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           (None, 170)               0         \n",
            "_________________________________________________________________\n",
            "embedding_26 (Embedding)     (None, 170, 899)          809100    \n",
            "_________________________________________________________________\n",
            "conv1d_145 (Conv1D)          (None, 168, 256)          690688    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_187 (LeakyReLU)  (None, 168, 256)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_74 (MaxPooling (None, 56, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_146 (Conv1D)          (None, 54, 256)           196864    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_188 (LeakyReLU)  (None, 54, 256)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_75 (MaxPooling (None, 18, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_147 (Conv1D)          (None, 16, 256)           196864    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_189 (LeakyReLU)  (None, 16, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_148 (Conv1D)          (None, 14, 256)           196864    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_190 (LeakyReLU)  (None, 14, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_149 (Conv1D)          (None, 12, 256)           196864    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_191 (LeakyReLU)  (None, 12, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_150 (Conv1D)          (None, 10, 256)           196864    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_192 (LeakyReLU)  (None, 10, 256)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_76 (MaxPooling (None, 3, 256)            0         \n",
            "_________________________________________________________________\n",
            "flatten_24 (Flatten)         (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense_66 (Dense)             (None, 1024)              787456    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_193 (LeakyReLU)  (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout_43 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_67 (Dense)             (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_194 (LeakyReLU)  (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout_44 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_68 (Dense)             (None, 3)                 3075      \n",
            "=================================================================\n",
            "Total params: 4,324,239\n",
            "Trainable params: 4,324,239\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Fwj-t4_qGcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.callbacks import Callback\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
        "\n",
        "class Metrics(Callback):\n",
        "  def __init__(self, logs={}):\n",
        "    self.val_f1s = []\n",
        "    self.val_recalls = []\n",
        "    self.val_precisions = []\n",
        " \n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    val_predict = (np.asarray(self.model.predict(x_test))).round()\n",
        "    val_targ = y_test\n",
        "    _val_f1 = f1_score(val_targ, val_predict,average=None)\n",
        "    _val_recall = recall_score(val_targ, val_predict,average=None)\n",
        "    _val_precision = precision_score(val_targ, val_predict,average=None)\n",
        "    self.val_f1s.append(_val_f1)\n",
        "    self.val_recalls.append(_val_recall)\n",
        "    self.val_precisions.append(_val_precision)\n",
        "    print(\" f1_score_Class1: %f \\t f1_score_Class2: %f \\t f1_score_Class3: %f \\n precision_Class1: %f \\t precision_Class2: %f \\t precision_Class3: %f \\n recall_Class1 %f \\t recall_Class2 %f \\t recall_Class3 %f\" %(_val_f1[0], _val_f1[1], _val_f1[2], _val_precision[0], _val_precision[1], _val_precision[2], _val_recall[0], _val_recall[1], _val_recall[2]))\n",
        "    return\n",
        " \n",
        "metrics = Metrics()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RWsR1-JqMp1",
        "colab_type": "code",
        "outputId": "b6f5471e-366f-449a-9a29-c8dd26fba636",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        }
      },
      "source": [
        "model.fit(x_train, y_train,validation_data=(x_test, y_test),batch_size=64,epochs=8,verbose=1,callbacks=[metrics])"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15130 samples, validate on 1868 samples\n",
            "Epoch 1/8\n",
            "15130/15130 [==============================] - 325s 21ms/step - loss: 1.0560 - acc: 0.4341 - val_loss: 1.0184 - val_acc: 0.4732\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " f1_score_Class1: 0.445328 \t f1_score_Class2: 0.000000 \t f1_score_Class3: 0.176183 \n",
            " precision_Class1: 0.528302 \t precision_Class2: 0.000000 \t precision_Class3: 0.666667 \n",
            " recall_Class1 0.384880 \t recall_Class2 0.000000 \t recall_Class3 0.101504\n",
            "Epoch 2/8\n",
            "15130/15130 [==============================] - 316s 21ms/step - loss: 0.9454 - acc: 0.5234 - val_loss: 1.0014 - val_acc: 0.4946\n",
            " f1_score_Class1: 0.404281 \t f1_score_Class2: 0.000000 \t f1_score_Class3: 0.519126 \n",
            " precision_Class1: 0.656371 \t precision_Class2: 0.000000 \t precision_Class3: 0.503534 \n",
            " recall_Class1 0.292096 \t recall_Class2 0.000000 \t recall_Class3 0.535714\n",
            "Epoch 3/8\n",
            "15130/15130 [==============================] - 319s 21ms/step - loss: 0.8902 - acc: 0.5614 - val_loss: 0.9748 - val_acc: 0.5241\n",
            " f1_score_Class1: 0.526515 \t f1_score_Class2: 0.015707 \t f1_score_Class3: 0.298817 \n",
            " precision_Class1: 0.586498 \t precision_Class2: 0.600000 \t precision_Class3: 0.701389 \n",
            " recall_Class1 0.477663 \t recall_Class2 0.007958 \t recall_Class3 0.189850\n",
            "Epoch 4/8\n",
            "15130/15130 [==============================] - 322s 21ms/step - loss: 0.8450 - acc: 0.5970 - val_loss: 1.0010 - val_acc: 0.5364\n",
            " f1_score_Class1: 0.566164 \t f1_score_Class2: 0.375538 \t f1_score_Class3: 0.502165 \n",
            " precision_Class1: 0.552288 \t precision_Class2: 0.535627 \t precision_Class3: 0.591837 \n",
            " recall_Class1 0.580756 \t recall_Class2 0.289125 \t recall_Class3 0.436090\n",
            "Epoch 5/8\n",
            "15130/15130 [==============================] - 322s 21ms/step - loss: 0.7977 - acc: 0.6288 - val_loss: 0.9986 - val_acc: 0.5294\n",
            " f1_score_Class1: 0.567944 \t f1_score_Class2: 0.238994 \t f1_score_Class3: 0.575729 \n",
            " precision_Class1: 0.575972 \t precision_Class2: 0.570000 \t precision_Class3: 0.576271 \n",
            " recall_Class1 0.560137 \t recall_Class2 0.151194 \t recall_Class3 0.575188\n",
            "Epoch 6/8\n",
            "15130/15130 [==============================] - 318s 21ms/step - loss: 0.7462 - acc: 0.6600 - val_loss: 1.0110 - val_acc: 0.5203\n",
            " f1_score_Class1: 0.558952 \t f1_score_Class2: 0.528624 \t f1_score_Class3: 0.301775 \n",
            " precision_Class1: 0.568384 \t precision_Class2: 0.488739 \t precision_Class3: 0.708333 \n",
            " recall_Class1 0.549828 \t recall_Class2 0.575597 \t recall_Class3 0.191729\n",
            "Epoch 7/8\n",
            "15130/15130 [==============================] - 323s 21ms/step - loss: 0.6798 - acc: 0.6958 - val_loss: 1.1105 - val_acc: 0.5252\n",
            " f1_score_Class1: 0.481707 \t f1_score_Class2: 0.513376 \t f1_score_Class3: 0.538168 \n",
            " precision_Class1: 0.589552 \t precision_Class2: 0.493873 \t precision_Class3: 0.546512 \n",
            " recall_Class1 0.407216 \t recall_Class2 0.534483 \t recall_Class3 0.530075\n",
            "Epoch 8/8\n",
            "15130/15130 [==============================] - 322s 21ms/step - loss: 0.5855 - acc: 0.7516 - val_loss: 1.1401 - val_acc: 0.5252\n",
            " f1_score_Class1: 0.565540 \t f1_score_Class2: 0.437547 \t f1_score_Class3: 0.507553 \n",
            " precision_Class1: 0.543582 \t precision_Class2: 0.509700 \t precision_Class3: 0.546638 \n",
            " recall_Class1 0.589347 \t recall_Class2 0.383289 \t recall_Class3 0.473684\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f003781ceb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    }
  ]
}